\label{Section:related work}
Energy-efficiency has become a critical concern for HPC applications. There are many approaches have been proposed to obtaining energy savings during HPC application execution. Some of them are to focus on identifying stalls during the execution by measuring architectural parameters from performance counters as proposed in\cite{ge2007cpu,hsu2005power,huang2009energy}. In addition to using performance counters, Rountree et al.\cite{rountree2009adagio} developed a runtime system called Adagio, by doing the critical path analysis, it can determine which tasks may be slowed down and also suitable opportunities to apply DVFS to minimize the performance loss in the parallel execution. This achieves significant energy saving in scientific application with negligible performance lose. However, this approach appears beneficial when applications have computation or communication imbalances among participating processes, which is typically not the case for a highly efficient parallel application nor suitable for the LMC program targeted in this work. Some approaches in\cite{freeh2005using,lim2006adaptive} are proposing to determine the communication phases to apply DVFS. Kandalla et al.\cite{kandalla2010designing} give algorithms to save energy in the collectives such as MPI\_Alltoall and MPI\_Bcase. Moreover, Ioannou et al.\cite{ioannou2011phase} describe a runtime system for the Intel Single-chip Cloud Computer (SCC) processor to detect repeatable communication phases followed by an application of frequency scaling. Donofrio et al.\cite{donofrio2009energy} have studied energy efficiency for extreme-scale science and developed Green Flash, an application-driven design to improve the kernelâ€™s computational efficiency. Li et al.\cite{li2010hybrid} developed a new power-aware performance prediction model of hybrid MPI/OpenMP programming model and combine memory and disk management techniques to provide performance guarantees for control algorithms. Rodero et al.\cite{rodero2010investigating} explored the potential of application-centric aggressive power management of HPC scientific workloads while considering power management mechanisms and controls available at different levels and different subsystems. Gmall et al.\cite{gamell2013exploring} explored data-related energy/performance trade-offs for end-to-end co-design simulation workflows on current and on-going high-end computing systems. Lively et al.\cite{lively2011energy} explored and investigated energy consumption and execution time of different parallel implementation of scientific applications on multi-cluster systems. 

Most of the work described above are from system level and are based on tolerating performance loss and constrain the power consumption under that performance loss. The work presented here discusses the possibility to filter down power constraint to job-level, and then take advantage of applications specific properties, such as resolution, to keep the power budget while maintaining the level of performance. 





The cost of provisioning power in data centers is a very large fraction of the total cost of operating a data center.\cite{pelley2010power,hamilton2008cost} Therefore the ability to cap peak power consumption is a desirable feature in modern data centers.\cite{cochran2011pack} Many power management approaches have been proposed to provide performance guarantees while constraining power budget. Sartori et al.\cite{sartori2009distributed} describe a peak power management technique for multi-core systems by choosing the power state for each core that meets the power constraints. Cebrian et al.\cite{cebrian2011power} develop a power balancing strategy that through borrowing power budgets from cores that consume lower power to dynamically adapts the per-core power budgets. While, Gandhi et al.\cite{gandhi2009power} give a power capping strategy to meet the power budget by inserting idle cycles during execution. This approach aims at controlling the average power consumption, but cannot guarantee the peak power. So a number of other approaches are proposed through reconfiguring hardware to meet the power budget. Meng et al.\cite{meng2008multi} provide a power management strategy through dynamic reconfiguration of cores by cache resizing. Konotorinis et al.\cite{kontorinis2009reducing} propose a table-driven adaptive core reconfiguration technique that configures core resources such as load-store queues and floating point units to meet peak power budget. Most of the power management strategies are using DVFS. Since Intel SandyBridge family processors, Intel provide Running Average Power Limit (RAPL) for controlling the power constraint on processors and memory. Several studies have begun to evaluate the RAPL power management system. Rountree et al.\cite{rountree2012beyond} explore RAPL as a replacement for DVFS in HPC systems by evaluating power consumption for package and memory subsystem. Zhang et al.\cite{zhang2015quantitative} give a systematic evaluation of RAPL behavior such as stability, setting time, overshoot and, etc. RAPL also been used to study application runtime variability and power optimization for exascale computing in work of Allan et al.\cite{porterfield2015application}[21] Sarood et al.\cite{sarood2013optimizing} use RAPL to set power bounds on across an over-provisioned cluster running homogeneous application processes.  This work also takes advantage of RAPL power controlling ability to dynamically manage power consumption.



Measuring the power/energy consumption of software components is the key for energy-aware scheduling, accounting and budgeting. RAPL measurement mechanism is described in\cite{porterfield2015application} and Marcus et al.\cite{hahnel2012measuring} has investigated the RAPL measurements performance and discussed the practical obstacles that existed in performing these measurements on complex modern CPUs. Vignesh et al.\cite{adhinarayanan2015greenness} studied the greenness of the in-situ and the post-processing visualization pipelines using RAPL to measure the CPUs and RAMs power consumption and with an average error rate of less than 1\%. Venkatesh et al.\cite{venkatesh2013evaluation} use RAPL to measure energy consumption in large message-passing applications.
